{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c6643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Del b\n",
    "for i, func in enumerate(func_list):\n",
    "\n",
    "    #Splits 1/5 for testing and 4/5 for training\n",
    "    X_train, X_test, z_train, z_test = train_test_split(X,z,test_size=0.3)\n",
    "    X_train_scaled, X_test_scaled, z_train_scaled, z_test_scaled = func(X_train, X_test, z_train, z_test)\n",
    "\n",
    "    #finner beta\n",
    "    beta = find_beta(X_train_scaled, z_train_scaled)\n",
    "    #Her er z_ vår forutsigelse\n",
    "    z_ = X_test_scaled @ beta\n",
    "\n",
    "    #Find estimated of quality of fmodel fit \n",
    "    scores_OLS_scaled[i, 0] = MSE(z_test_scaled, z_)\n",
    "    scores_OLS_scaled[i, 1] = R2(z_test_scaled, z_)\n",
    "\n",
    "d1 = pd.DataFrame(scores_OLS_scaled, columns = ('MSE test', 'R2 test')) \n",
    "d = pd.concat([d1], axis =1)\n",
    "names = ['Standard', 'Mean', 'MinMax', 'Robustscaler', 'None']\n",
    "d['scaler'] = names\n",
    "d[['scaler', 'MSE test','R2 test']].set_index('scaler')\n",
    "display(d)\n",
    "\n",
    "#del c\n",
    "scores_OLS_boot = np.zeros((maxdegree, 2))\n",
    "degrees = np.linspace(1, maxdegree, maxdegree, dtype=int)\n",
    "metrics = {'degree': degrees,'error': [], 'bias': [], 'variance': []}\n",
    "\n",
    "for degree in degrees:\n",
    "    X = create_X(x, y, degree)\n",
    "    X_train, X_test, z_train, z_test = train_test_split(X,z,test_size=1/4)\n",
    "    \n",
    "    boot_n = 50\n",
    "\n",
    "    bt_MSE, bt_R2, error, bias, var = bootstrap(X_train,z_train,X_test, z_test, iterations = boot_n) #bootstrapping the z-values to get a resampled set of the 'observed' data\n",
    "    metrics['error'].append(error)\n",
    "    metrics['bias'].append(bias)\n",
    "    metrics['variance'].append(var)\n",
    "    \n",
    "\n",
    "    scores_OLS_boot[degree-1, 0] = bt_MSE\n",
    "    scores_OLS_boot[degree-1, 1] = bt_R2\n",
    "    #print(f\"Errors for degree {degree}:\")\n",
    "    #print(f\"MSE[Bootstrap] = {scores_OLS_boot[degree-1, 0]}\")\n",
    "    #print(f\"MSE[w/0 resampling] = {scores_OLS_basic[degree-1, 0]}\")\n",
    "    #print(f\"R2[Bootstrap] = {scores_OLS_boot[degree-1, 1]}\")\n",
    "    #print(f\"R2[w/o resampling] = {scores_OLS_basic[degree-1, 1]}\")\n",
    "    #print(f\"Improvement:\")\n",
    "    #print(f\"RMSE: {abs(scores_OLS_boot[degree-1, 0] - scores_OLS_basic[degree-1, 0])}\")\n",
    "    #print(f\"R2: {abs(scores_OLS_boot[degree-1, 1] - scores_OLS_basic[degree-1, 1])}\\n\")\n",
    "\n",
    "    \n",
    "estimates = pd.DataFrame(scores_OLS_boot, columns=['bt_MSE', 'bt_R2'])\n",
    "bt_results = pd.concat([pd.DataFrame(metrics), estimates], axis = 1)\n",
    "bt_results = bt_results.set_index('degree')\n",
    "display(bt_results)\n",
    "#error = scores_OLS_boot[maxdegree-1, 0]**2 #for each of the degrees, the MSE is used to get an error estimate\n",
    "# finding the bias by subtractiong the mean of the bootstraped predictions from each test-data value,\n",
    "# then calculating the mean of this - ideally it should be 0, indicating that the predictions are nomally distributed\n",
    "# around the predictions\n",
    "\n",
    "#print('Error:', error)\n",
    "#print('Bias^2:', bias)\n",
    "#print('Var:', variance)\n",
    "degree7 = bt_results.loc[7]\n",
    "\n",
    "plt.plot(degrees, scores_OLS_basic[:, 0], label=\"OLS w/o resampling\")\n",
    "plt.plot(degrees, scores_OLS_boot[:, 0], label=\"OLS w/ Bootstrap\")\n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"MSE score\")\n",
    "plt.legend()\n",
    "plt.title('Mean Squared Error as function of complexity')\n",
    "\n",
    "plt.plot(degrees, bt_results['bias'], label=\"Boot bias\")\n",
    "plt.plot(degrees,  bt_results['error'], label=\"Boot error\")\n",
    "plt.plot(degrees,  bt_results['variance'], label=\"Boot variance\")\n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"\")\n",
    "plt.legend()\n",
    "plt.title('Mean Squared Error as function of complexity')\n",
    "\n",
    "#del d\n",
    "kfolds = 5\n",
    "scores_OLS_CV = np.zeros((maxdegree, 1))\n",
    "MSE_degrees = []\n",
    "for degree in degrees:\n",
    "    #denne gangen deler vi ikke inn i train og test\n",
    "    #men vi kunne gjort det også, for enda et lag med vurdering\n",
    "    #dette kan være nyttig for høye grader av maxdegree\n",
    "    \n",
    "    X = create_X(x, y, degree)\n",
    "    #scores, z_, X_test, z_test = cross_validation(X, z, kfolds)\n",
    "    scores,MSE_cv = cross_validation(X, z, kfolds)\n",
    "    #print('scores: ', scores)\n",
    "    scores_OLS_CV[degree-1, 0] = MSE_cv \n",
    "    #MSE_degrees.append(MSE_cv)\n",
    "    #scores_OLS_CV[degree-1, 1] = R2(z_test, z_)\n",
    "    '''print(f\"Errors for degree {degree}:\")\n",
    "    print(f\"RMSE[CV] = {scores_OLS_CV[degree-1, 0]}\")\n",
    "    print(f\"RMSE[w/0 resampling] = {scores_OLS_basic[degree-1, 0]}\")\n",
    "    print(f\"R2[CV] = {scores_OLS_CV[degree-1, 1]}\")\n",
    "    print(f\"R2[w/o resampling] = {scores_OLS_basic[degree-1, 1]}\")\n",
    "    print(f\"Improvement:\")\n",
    "    print(f\"RMSE: {scores_OLS_basic[degree-1, 0] - scores_OLS_CV[degree-1, 0]}\")\n",
    "    print(f\"R2: {scores_OLS_CV[degree-1, 1] - scores_OLS_basic[degree-1, 1]}\\n\")'''\n",
    " \n",
    "datf = pd.DataFrame({'MSE_cv': scores_OLS_CV[:,0], 'degree': degrees}).set_index('degree')\n",
    "display(pd.concat([datf, bt_results], axis=1))\n",
    "\n",
    "plt.plot(degrees, scores_OLS_basic[:, 0], label=\"OLS w/o resampling\")\n",
    "plt.plot(degrees, scores_OLS_boot[:, 0], label=\"OLS w/ Bootstrap\")\n",
    "plt.plot(degrees, scores_OLS_CV[:, 0], label=\"OLS w/ CV\")\n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"RMSE score\")\n",
    "plt.legend()\n",
    "\n",
    "#del e\n",
    "N = 5\n",
    "#fra 10^-4 til 10^4, tar kun verdier 10^n, hvor n er et heltall\n",
    "lmbda = np.logspace(-4, 4, N)\n",
    "\n",
    "#scores_Ridge_boot = np.zeros((maxdegree, 2, N))\n",
    "scores_Ridge_boot = np.zeros((maxdegree, 1)) #Bare droppa å lagre R2 ogsp for jeg vet ikke om det trengs\n",
    "best_i = np.zeros(maxdegree, dtype=int)\n",
    "for degree in degrees:\n",
    "    X = create_X(x, y, degree)\n",
    "    X_train, X_test, z_train, z_test = train_test_split(X,z,test_size=0.2)\n",
    "    \n",
    "    #her utfører vi bootstrap\n",
    "    B = len(z_train)\n",
    "    z_train_boot = np.zeros(B)\n",
    "    X_train_boot = np.zeros(X_train.shape)\n",
    "    #for i in range(B):\n",
    "     #   X_train_boot[i], z_train_boot[i] = bootstrap(X_train, z_train)\n",
    "    mse_lambs, lmbd_outs = bootstrap(X_train, z_train, X_test, z_test, reg = 'ridge', lamb = True)    \n",
    "    #itererer over alle lambda og bruker det feature matrise og data etter bootstrap\n",
    "    '''for i, lmbda_ in enumerate(lmbda):\n",
    "        beta = ridge_regression(X_train_boot, z_train_boot, lmbda_)\n",
    "        z_ = X_test @ beta\n",
    "        scores_Ridge_boot[degree-1, 0, i] = np.sqrt(MSE(z_test, z_))\n",
    "        scores_Ridge_boot[degree-1, 1, i] = R2(z_test, z_)\n",
    "        if i > 0:\n",
    "            if scores_Ridge_boot[degree-1, 0, i] < scores_Ridge_boot[degree-1, 0, best_i[degree-1]]:\n",
    "                best_i[degree-1] = i'''\n",
    "        \n",
    "    #her skal jeg legge inn slik at vi også gjør CV\n",
    "    #lamb_df = pd.DataFrame({'mse_lamb': mse_lambs, 'lambdas': lmbd_outs})\n",
    "    #display(lamb_df)\n",
    "    scores_Ridge_boot[degree-1, 0] = min(mse_lambs)\n",
    "    #print(f\"Errors for degree {degree}:\")\n",
    "    #print(f\"RMSE[Bootstrap] = {scores_Ridge_boot[degree-1, 0, best_i[degree-1]]}\")\n",
    "    #print(f\"RMSE[w/0 resampling] = {scores_OLS_basic[degree-1, 0]}\")\n",
    "    #print(f\"R2[Bootstrap] = {scores_Ridge_boot[degree-1, 1, best_i[degree-1]]}\")\n",
    "    #print(f\"R2[w/o resampling] = {scores_OLS_basic[degree-1, 1]}\")\n",
    "    #print(f\"Improvement:\")\n",
    "    #print(f\"RMSE: {scores_OLS_basic[degree-1, 0] - scores_Ridge_boot[degree-1, 0, best_i[degree-1]]}\")\n",
    "    #print(f\"R2: {scores_Ridge_boot[degree-1, 1, best_i[degree-1]] - scores_OLS_basic[degree-1, 1]}\\n\")\n",
    "\n",
    "#print(scores_Ridge_boot)    \n",
    "lamb_df = pd.DataFrame({'mse_lamb': scores_Ridge_boot[:, 0], 'degree': degrees})\n",
    "display(lamb_df)\n",
    "\n",
    "fig, ax = plt.subplots(int(N/2), int(N/2)+N%2, figsize= (12, 12))\n",
    "\n",
    "for i in range(N):\n",
    "    ax.flatten()[i].plot(degrees, scores_OLS_basic[:, 0], label=\"OLS w/o resampling\")\n",
    "    ax.flatten()[i].plot(degrees, scores_OLS_boot[:, 0], label=\"OLS w/ Bootstrap\")\n",
    "    ax.flatten()[i].plot(degrees, scores_OLS_CV[:, 0], label=\"OLS w/ CV\")\n",
    "    ax.flatten()[i].plot(degrees, scores_Ridge_boot[:, 0], label=\"Ridge w/ Bootstrap\")\n",
    "    ax.flatten()[i].set_xlabel(\"Degree\")\n",
    "    if i%(int(N/2)+1) == 0:\n",
    "        ax.flatten()[i].set_ylabel(\"RMSE score\")\n",
    "    ax.flatten()[i].set_title(fr\"$\\lambda = ${lmbda[i]}\")\n",
    "    \n",
    "\n",
    "handles, labels = ax.flatten()[i].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='center right')\n",
    "\n",
    "N = 5\n",
    "lmbda = np.logspace(-4, 4, N)\n",
    "\n",
    "scores_Lasso_boot = np.zeros((maxdegree, 2, N))\n",
    "best_i = np.zeros(maxdegree, dtype=int)\n",
    "for degree in degrees:\n",
    "    X = create_X(x, y, degree)\n",
    "    X_train, X_test, z_train, z_test = train_test_split(X,z,test_size=0.2)\n",
    "    #X_train, X_test = meanscaler(X_train), meanscaler(X_test)\n",
    "    \n",
    "    B = len(z_train)\n",
    "    z_train_boot = np.zeros(B)\n",
    "    X_train_boot = np.zeros(X_train.shape)\n",
    "    \n",
    "    mse_lambs, lmbd_outs = bootstrap(X_train, z_train, X_test, z_test, reg = 'lasso')\n",
    "    scores_Lasso_boot[degree-1, 0] = min(mse_lambs)\n",
    "    \n",
    "lamb_df = pd.DataFrame({'mse_lamb': scores_Lasso_boot[:, 0], 'degree': degrees})\n",
    "display(lamb_df)\n",
    "\n",
    "fig, ax = plt.subplots(int(N/2), int(N/2)+N%2, figsize= (12, 12))\n",
    "\n",
    "for i in range(N):\n",
    "    ax.flatten()[i].plot(degrees, scores_OLS_basic[:, 0], label=\"OLS w/o resampling\")\n",
    "    ax.flatten()[i].plot(degrees, scores_OLS_boot[:, 0], label=\"OLS w/ Bootstrap\")\n",
    "    ax.flatten()[i].plot(degrees, scores_OLS_CV[:, 0], label=\"OLS w/ CV\")\n",
    "    ax.flatten()[i].plot(degrees, scores_Ridge_boot[:, 0], label=\"Ridge w/ Bootstrap\")\n",
    "    ax.flatten()[i].plot(degrees, scores_Lasso_boot[:, 0], label=\"Lasso w/ Bootstrap\")\n",
    "    ax.flatten()[i].set_xlabel(\"Degree\")\n",
    "    if i%(int(N/2)+1) == 0:\n",
    "        ax.flatten()[i].set_ylabel(\"RMSE score\")\n",
    "    ax.flatten()[i].set_title(fr\"$\\lambda = ${lmbda[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
