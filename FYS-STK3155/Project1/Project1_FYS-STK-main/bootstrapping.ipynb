{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42ea5a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b1d2e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FrankeFunction(x,y):\n",
    "    term1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n",
    "    term2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))\n",
    "    term3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))\n",
    "    term4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n",
    "    return term1 + term2 + term3 + term4 + np.random.normal(0, 0.1, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00d1daab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def R2(y_data, y_model):\n",
    "    return 1 - np.sum((y_data - y_model)**2) / np.sum((y_data - np.mean(y_data)) ** 2)\n",
    "\n",
    "def MSE(y_data,y_model):\n",
    "    n = np.size(y_model)\n",
    "    return np.sum((y_data-y_model)**2)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3f7242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X(x, y, n):\n",
    "    if len(x.shape) > 1:\n",
    "        x = np.ravel(x) # flattens the matrices\n",
    "        y = np.ravel(y)\n",
    "\n",
    "    N = len(x) #number of x-variables, datapoints\n",
    "    l = int((n+1)*(n+2)/2)     # Number of elements in beta - parameters, features\n",
    "    X = np.ones((N,l)) #Making a matrix of dimentions given by the number of variables and number of parameters\n",
    "\n",
    "    for i in range(1,n+1):\n",
    "        q = int((i)*(i+1)/2)\n",
    "        for k in range(i+1):\n",
    "            X[:,q+k] = (x**(i-k))*(y**k)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d58cfdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_beta(X, z): \n",
    "    XT = X.T\n",
    "    XTXinv = np.linalg.pinv(np.matmul(XT, X))\n",
    "    XTz = np.matmul(XT, z)\n",
    "    beta = np.matmul(XTXinv, XTz)\n",
    "\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fad4ce0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 2000 2000\n"
     ]
    }
   ],
   "source": [
    "size = 2000\n",
    "noise = 0.05 # Level of noise\n",
    "x = np.arange(0, 1, 1/size)\n",
    "y = np.arange(0, 1, 1/size)\n",
    "#x, y = np.meshgrid(x,y)\n",
    "\n",
    "z = FrankeFunction(x, y)\n",
    "z += (np.random.randn(size)*noise) #Added noise\n",
    "print(len(x), len(y), len(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b1a97d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "'''def bootstrap(x, z, x_test, z_test, iterations = 100):\n",
    "    MSEs = np.zeros(iterations) \n",
    "    R2s = np.zeros(iterations) \n",
    "    z_preds= []\n",
    "    for i in range(iterations):\n",
    "        bt_x, bt_z = resample(x, z)\n",
    "        beta = find_beta(bt_x, bt_z) #Finding beta with new x train and z train\n",
    "        z_pred = x_test @ beta #predict z with x_test\n",
    "        z_preds.append(z_pred)\n",
    "        mse = MSE(z_test, z_pred)\n",
    "        r2 = R2(z_test, z_pred) # getting statistics of prediction in current bootstrap\n",
    "        MSEs[i] = mse\n",
    "        R2s[i] = r2\n",
    "    \n",
    "    zpreds = np.mean(z_preds)\n",
    "    bt_err = np.mean( np.mean((z_test - z_preds)**2, axis=1, keepdims=True))\n",
    "    bt_bias = np.mean((z_test - np.mean(z_preds, axis=1, keepdims=True))**2)\n",
    "    bt_var = np.mean( np.var(z_preds) )\n",
    "    boot_MSE = np.mean(MSEs)\n",
    "    boot_R2 = np.mean(R2s)\n",
    "    \n",
    "    return boot_MSE, boot_R2, bt_err, bt_bias, bt_var\n",
    "from sklearn.utils import resample'''\n",
    "\n",
    "def bootstrap(x, z, x_test, z_test, iterations = 100):\n",
    "    MSEs = np.zeros(iterations) \n",
    "    R2s = np.zeros(iterations) \n",
    "    z_preds = np.zeros((len(z_test), iterations)) \n",
    "    for i in range(iterations):\n",
    "        bt_x, bt_z = resample(x, z)\n",
    "        beta = find_beta(bt_x, bt_z) #Finding beta with new x train and z train\n",
    "        z_pred = x_test @ beta #predict z with x_test\n",
    "        z_preds[:, i] = z_pred.ravel()\n",
    "        z_test = z_test.reshape((-1, 1))\n",
    "        mse = MSE(z_test, z_pred)\n",
    "        r2 = R2(z_test, z_pred) # getting statistics of prediction in current bootstrap\n",
    "        MSEs[i] = mse\n",
    "        R2s[i] = r2\n",
    "    \n",
    "    zpreds = z_preds.ravel()\n",
    "    bt_err = np.mean( np.mean((z_test - z_preds)**2, axis=1, keepdims=True))\n",
    "    bt_bias = np.mean((z_test - np.mean(z_preds, axis=1, keepdims=True))**2)\n",
    "    bt_var = np.mean( np.var(z_preds, axis=1, keepdims=True) )\n",
    "    #bt_var = np.mean( np.var(z_preds) )\n",
    "    boot_MSE = np.mean(MSEs)\n",
    "    boot_R2 = np.mean(R2s)\n",
    "    \n",
    "    return boot_MSE, boot_R2, bt_err, bt_bias, bt_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9af9352f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "      <th>bias</th>\n",
       "      <th>variance</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.039388</td>\n",
       "      <td>0.039335</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>164.235088</td>\n",
       "      <td>-877.394710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.046100</td>\n",
       "      <td>0.046017</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>166.185640</td>\n",
       "      <td>-865.480747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027391</td>\n",
       "      <td>0.027323</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>178.492255</td>\n",
       "      <td>-929.448440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017808</td>\n",
       "      <td>0.017746</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>172.409127</td>\n",
       "      <td>-939.098844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.017089</td>\n",
       "      <td>0.017021</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>176.933339</td>\n",
       "      <td>-975.343549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.014721</td>\n",
       "      <td>0.014664</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>181.935795</td>\n",
       "      <td>-977.289484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.014608</td>\n",
       "      <td>0.014534</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>181.341120</td>\n",
       "      <td>-973.986310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.013814</td>\n",
       "      <td>0.013737</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>180.676679</td>\n",
       "      <td>-962.622484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.012380</td>\n",
       "      <td>0.012311</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>183.618175</td>\n",
       "      <td>-960.376991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.012314</td>\n",
       "      <td>0.012207</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>171.513274</td>\n",
       "      <td>-971.553371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.012289</td>\n",
       "      <td>0.012197</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>170.725493</td>\n",
       "      <td>-969.772248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.011545</td>\n",
       "      <td>0.011438</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>175.077119</td>\n",
       "      <td>-981.534529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.012122</td>\n",
       "      <td>0.012003</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>184.303810</td>\n",
       "      <td>-982.335541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.012544</td>\n",
       "      <td>0.012448</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>190.793467</td>\n",
       "      <td>-942.166345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.012408</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>174.378072</td>\n",
       "      <td>-981.564044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.012902</td>\n",
       "      <td>0.012809</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>192.740865</td>\n",
       "      <td>-974.087380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.012220</td>\n",
       "      <td>0.012112</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>184.563803</td>\n",
       "      <td>-958.966248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.012518</td>\n",
       "      <td>0.012407</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>190.413432</td>\n",
       "      <td>-953.089203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.011318</td>\n",
       "      <td>0.011203</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>171.719036</td>\n",
       "      <td>-970.278854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.012720</td>\n",
       "      <td>0.012616</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>181.872698</td>\n",
       "      <td>-966.640213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           error      bias  variance         MSE          R2\n",
       "degree                                                      \n",
       "1       0.039388  0.039335  0.000053  164.235088 -877.394710\n",
       "2       0.046100  0.046017  0.000084  166.185640 -865.480747\n",
       "3       0.027391  0.027323  0.000068  178.492255 -929.448440\n",
       "4       0.017808  0.017746  0.000063  172.409127 -939.098844\n",
       "5       0.017089  0.017021  0.000068  176.933339 -975.343549\n",
       "6       0.014721  0.014664  0.000057  181.935795 -977.289484\n",
       "7       0.014608  0.014534  0.000074  181.341120 -973.986310\n",
       "8       0.013814  0.013737  0.000077  180.676679 -962.622484\n",
       "9       0.012380  0.012311  0.000069  183.618175 -960.376991\n",
       "10      0.012314  0.012207  0.000107  171.513274 -971.553371\n",
       "11      0.012289  0.012197  0.000092  170.725493 -969.772248\n",
       "12      0.011545  0.011438  0.000107  175.077119 -981.534529\n",
       "13      0.012122  0.012003  0.000119  184.303810 -982.335541\n",
       "14      0.012544  0.012448  0.000096  190.793467 -942.166345\n",
       "15      0.012408  0.012317  0.000091  174.378072 -981.564044\n",
       "16      0.012902  0.012809  0.000093  192.740865 -974.087380\n",
       "17      0.012220  0.012112  0.000108  184.563803 -958.966248\n",
       "18      0.012518  0.012407  0.000110  190.413432 -953.089203\n",
       "19      0.011318  0.011203  0.000115  171.719036 -970.278854\n",
       "20      0.012720  0.012616  0.000104  181.872698 -966.640213"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    error              bias                 variance        \n",
      "0.014608200052218134 >= 0.014534454660353954 + 7.374539186417966e-05 = 0.014608200052218134\n"
     ]
    }
   ],
   "source": [
    "maxdegree = 20\n",
    "scores_OLS_boot = np.zeros((maxdegree, 2))\n",
    "degrees = np.linspace(1, maxdegree, maxdegree, dtype=int)\n",
    "metrics = {'degree': degrees,'error': [], 'bias': [], 'variance': []}\n",
    "\n",
    "for degree in degrees:\n",
    "    X = create_X(x, y, degree)\n",
    "    X_train, X_test, z_train, z_test = train_test_split(X,z,test_size=1/4)\n",
    "    \n",
    "    boot_n = 50\n",
    "\n",
    "    bt_MSE, bt_R2, error, bias, var = bootstrap(X_train,z_train,X_test, z_test, iterations = boot_n) #bootstrapping the z-values to get a resampled set of the 'observed' data\n",
    "    metrics['error'].append(error)\n",
    "    metrics['bias'].append(bias)\n",
    "    metrics['variance'].append(var)\n",
    "    \n",
    "\n",
    "    scores_OLS_boot[degree-1, 0] = bt_MSE\n",
    "    scores_OLS_boot[degree-1, 1] = bt_R2\n",
    "\n",
    "    \n",
    "estimates = pd.DataFrame(scores_OLS_boot, columns=['MSE', 'R2'])\n",
    "bt_results = pd.concat([pd.DataFrame(metrics), estimates], axis = 1)\n",
    "bt_results = bt_results.set_index('degree')\n",
    "display(bt_results)\n",
    "\n",
    "degree7 = bt_results.loc[7]\n",
    "print('    error              bias                 variance        ')\n",
    "print('{} >= {} + {} = {}'.format(degree7['error'], degree7['bias'], degree7['variance'], degree7['bias']+ degree7['variance']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb45e470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54de07b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
